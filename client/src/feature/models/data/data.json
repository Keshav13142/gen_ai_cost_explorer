[
    {
      "model_name": "gpt-4",
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "gpt-4o",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "gpt-4o-mini",
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 6e-7,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "gpt-4o-mini-2024-07-18",
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 6e-7,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "chatgpt-4o-latest",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "gpt-4o-2024-05-13",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "gpt-4o-2024-08-06",
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.00001,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "gpt-4-turbo-preview",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    {
      "model_name": "gpt-4-0314",
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "openai",
      "mode": "chat"
    },
    {
      "model_name": "gpt-4-0613",
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "gpt-4-32k",
      "max_tokens": 4096,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "output_cost_per_token": 0.00012,
      "litellm_provider": "openai",
      "mode": "chat"
    },
    {
      "model_name": "gpt-4-32k-0314",
      "max_tokens": 4096,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "output_cost_per_token": 0.00012,
      "litellm_provider": "openai",
      "mode": "chat"
    },
    {
      "model_name": "gpt-4-32k-0613",
      "max_tokens": 4096,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "output_cost_per_token": 0.00012,
      "litellm_provider": "openai",
      "mode": "chat"
    },
    {
      "model_name": "gpt-4-turbo",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "gpt-4-turbo-2024-04-09",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "gpt-4-1106-preview",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    {
      "model_name": "gpt-4-0125-preview",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    {
      "model_name": "gpt-4-vision-preview",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_vision": true
    },
    {
      "model_name": "gpt-4-1106-vision-preview",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_vision": true
    },
    {
      "model_name": "gpt-3.5-turbo",
      "max_tokens": 4097,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "gpt-3.5-turbo-0301",
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "openai",
      "mode": "chat"
    },
    {
      "model_name": "gpt-3.5-turbo-0613",
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "gpt-3.5-turbo-1106",
      "max_tokens": 16385,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    {
      "model_name": "gpt-3.5-turbo-0125",
      "max_tokens": 16385,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    {
      "model_name": "gpt-3.5-turbo-16k",
      "max_tokens": 16385,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "openai",
      "mode": "chat"
    },
    {
      "model_name": "gpt-3.5-turbo-16k-0613",
      "max_tokens": 16385,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "openai",
      "mode": "chat"
    },
    {
      "model_name": "ft:gpt-3.5-turbo",
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000006,
      "litellm_provider": "openai",
      "mode": "chat"
    },
    {
      "model_name": "ft:gpt-4-0613",
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "OpenAI needs to add pricing for this ft model, will be updated when added by OpenAI. Defaulting to base model pricing"
    },
    {
      "model_name": "ft:gpt-4o-mini-2024-07-18",
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 0.0000012,
      "litellm_provider": "openai",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "ft:davinci-002",
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000002,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "text-completion-openai",
      "mode": "completion"
    },
    {
      "model_name": "ft:babbage-002",
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 4e-7,
      "output_cost_per_token": 4e-7,
      "litellm_provider": "text-completion-openai",
      "mode": "completion"
    },
    {
      "model_name": "text-embedding-3-large",
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "output_vector_size": 3072,
      "input_cost_per_token": 1.3e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "openai",
      "mode": "embedding"
    },
    {
      "model_name": "text-embedding-3-small",
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "output_vector_size": 1536,
      "input_cost_per_token": 2e-8,
      "output_cost_per_token": 0,
      "litellm_provider": "openai",
      "mode": "embedding"
    },
    {
      "model_name": "text-embedding-ada-002",
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "output_vector_size": 1536,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "openai",
      "mode": "embedding"
    },
    {
      "model_name": "text-embedding-ada-002-v2",
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "openai",
      "mode": "embedding"
    },
    {
      "model_name": "text-moderation-stable",
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 0,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "openai",
      "mode": "moderations"
    },
    {
      "model_name": "text-moderation-007",
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 0,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "openai",
      "mode": "moderations"
    },
    {
      "model_name": "text-moderation-latest",
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 0,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "openai",
      "mode": "moderations"
    },
    {
      "model_name": "256-x-256/dall-e-2",
      "mode": "image_generation",
      "input_cost_per_pixel": 2.4414e-7,
      "output_cost_per_pixel": 0,
      "litellm_provider": "openai"
    },
    {
      "model_name": "512-x-512/dall-e-2",
      "mode": "image_generation",
      "input_cost_per_pixel": 6.86e-8,
      "output_cost_per_pixel": 0,
      "litellm_provider": "openai"
    },
    {
      "model_name": "1024-x-1024/dall-e-2",
      "mode": "image_generation",
      "input_cost_per_pixel": 1.9e-8,
      "output_cost_per_pixel": 0,
      "litellm_provider": "openai"
    },
    {
      "model_name": "hd/1024-x-1792/dall-e-3",
      "mode": "image_generation",
      "input_cost_per_pixel": 6.539e-8,
      "output_cost_per_pixel": 0,
      "litellm_provider": "openai"
    },
    {
      "model_name": "hd/1792-x-1024/dall-e-3",
      "mode": "image_generation",
      "input_cost_per_pixel": 6.539e-8,
      "output_cost_per_pixel": 0,
      "litellm_provider": "openai"
    },
    {
      "model_name": "hd/1024-x-1024/dall-e-3",
      "mode": "image_generation",
      "input_cost_per_pixel": 7.629e-8,
      "output_cost_per_pixel": 0,
      "litellm_provider": "openai"
    },
    {
      "model_name": "standard/1024-x-1792/dall-e-3",
      "mode": "image_generation",
      "input_cost_per_pixel": 4.359e-8,
      "output_cost_per_pixel": 0,
      "litellm_provider": "openai"
    },
    {
      "model_name": "standard/1792-x-1024/dall-e-3",
      "mode": "image_generation",
      "input_cost_per_pixel": 4.359e-8,
      "output_cost_per_pixel": 0,
      "litellm_provider": "openai"
    },
    {
      "model_name": "standard/1024-x-1024/dall-e-3",
      "mode": "image_generation",
      "input_cost_per_pixel": 3.81469e-8,
      "output_cost_per_pixel": 0,
      "litellm_provider": "openai"
    },
    {
      "model_name": "whisper-1",
      "mode": "audio_transcription",
      "input_cost_per_second": 0,
      "output_cost_per_second": 0.0001,
      "litellm_provider": "openai"
    },
    {
      "model_name": "tts-1",
      "mode": "audio_speech",
      "input_cost_per_character": 0.000015,
      "litellm_provider": "openai"
    },
    {
      "model_name": "tts-1-hd",
      "mode": "audio_speech",
      "input_cost_per_character": 0.00003,
      "litellm_provider": "openai"
    },
    {
      "model_name": "azure/tts-1",
      "mode": "audio_speech",
      "input_cost_per_character": 0.000015,
      "litellm_provider": "azure"
    },
    {
      "model_name": "azure/tts-1-hd",
      "mode": "audio_speech",
      "input_cost_per_character": 0.00003,
      "litellm_provider": "azure"
    },
    {
      "model_name": "azure/whisper-1",
      "mode": "audio_transcription",
      "input_cost_per_second": 0,
      "output_cost_per_second": 0.0001,
      "litellm_provider": "azure"
    },
    {
      "model_name": "azure/gpt-4o",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "azure/global-standard/gpt-4o-mini",
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 6e-7,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "azure/gpt-4o-mini",
      "max_tokens": 16384,
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.65e-7,
      "output_cost_per_token": 6.6e-7,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "azure/gpt-4-turbo-2024-04-09",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "azure/gpt-4-0125-preview",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    {
      "model_name": "azure/gpt-4-1106-preview",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    {
      "model_name": "azure/gpt-4-0613",
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "azure/gpt-4-32k-0613",
      "max_tokens": 4096,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "output_cost_per_token": 0.00012,
      "litellm_provider": "azure",
      "mode": "chat"
    },
    {
      "model_name": "azure/gpt-4-32k",
      "max_tokens": 4096,
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "output_cost_per_token": 0.00012,
      "litellm_provider": "azure",
      "mode": "chat"
    },
    {
      "model_name": "azure/gpt-4",
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "azure/gpt-4-turbo",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    {
      "model_name": "azure/gpt-4-turbo-vision-preview",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_vision": true
    },
    {
      "model_name": "azure/gpt-35-turbo-16k-0613",
      "max_tokens": 4096,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "azure/gpt-35-turbo-1106",
      "max_tokens": 4096,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    {
      "model_name": "azure/gpt-35-turbo-0125",
      "max_tokens": 4096,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    {
      "model_name": "azure/gpt-35-turbo-16k",
      "max_tokens": 4096,
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "azure",
      "mode": "chat"
    },
    {
      "model_name": "azure/gpt-35-turbo",
      "max_tokens": 4096,
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "azure/gpt-3.5-turbo-instruct-0914",
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "text-completion-openai",
      "mode": "completion"
    },
    {
      "model_name": "azure/gpt-35-turbo-instruct",
      "max_tokens": 4097,
      "max_input_tokens": 4097,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "text-completion-openai",
      "mode": "completion"
    },
    {
      "model_name": "azure/mistral-large-latest",
      "max_tokens": 32000,
      "max_input_tokens": 32000,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "azure/mistral-large-2402",
      "max_tokens": 32000,
      "max_input_tokens": 32000,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "azure/command-r-plus",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "azure",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "azure/ada",
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "azure",
      "mode": "embedding"
    },
    {
      "model_name": "azure/text-embedding-ada-002",
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "azure",
      "mode": "embedding"
    },
    {
      "model_name": "azure/text-embedding-3-large",
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 1.3e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "azure",
      "mode": "embedding"
    },
    {
      "model_name": "azure/text-embedding-3-small",
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "input_cost_per_token": 2e-8,
      "output_cost_per_token": 0,
      "litellm_provider": "azure",
      "mode": "embedding"
    },
    {
      "model_name": "azure/standard/1024-x-1024/dall-e-3",
      "input_cost_per_pixel": 3.81469e-8,
      "output_cost_per_token": 0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    {
      "model_name": "azure/hd/1024-x-1024/dall-e-3",
      "input_cost_per_pixel": 7.629e-8,
      "output_cost_per_token": 0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    {
      "model_name": "azure/standard/1024-x-1792/dall-e-3",
      "input_cost_per_pixel": 4.359e-8,
      "output_cost_per_token": 0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    {
      "model_name": "azure/standard/1792-x-1024/dall-e-3",
      "input_cost_per_pixel": 4.359e-8,
      "output_cost_per_token": 0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    {
      "model_name": "azure/hd/1024-x-1792/dall-e-3",
      "input_cost_per_pixel": 6.539e-8,
      "output_cost_per_token": 0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    {
      "model_name": "azure/hd/1792-x-1024/dall-e-3",
      "input_cost_per_pixel": 6.539e-8,
      "output_cost_per_token": 0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    {
      "model_name": "azure/standard/1024-x-1024/dall-e-2",
      "input_cost_per_pixel": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "azure",
      "mode": "image_generation"
    },
    {
      "model_name": "azure_ai/jamba-instruct",
      "max_tokens": 4096,
      "max_input_tokens": 70000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 7e-7,
      "litellm_provider": "azure_ai",
      "mode": "chat"
    },
    {
      "model_name": "azure_ai/mistral-large",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000004,
      "output_cost_per_token": 0.000012,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "azure_ai/mistral-small",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "azure_ai",
      "supports_function_calling": true,
      "mode": "chat"
    },
    {
      "model_name": "azure_ai/Meta-Llama-3-70B-Instruct",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0000011,
      "output_cost_per_token": 3.7e-7,
      "litellm_provider": "azure_ai",
      "mode": "chat"
    },
    {
      "model_name": "azure_ai/Meta-Llama-31-8B-Instruct",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 6.1e-7,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice"
    },
    {
      "model_name": "azure_ai/Meta-Llama-31-70B-Instruct",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.00000268,
      "output_cost_per_token": 0.00000354,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice"
    },
    {
      "model_name": "azure_ai/Meta-Llama-31-405B-Instruct",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.00000533,
      "output_cost_per_token": 0.000016,
      "litellm_provider": "azure_ai",
      "mode": "chat",
      "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice"
    },
    {
      "model_name": "babbage-002",
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 4e-7,
      "output_cost_per_token": 4e-7,
      "litellm_provider": "text-completion-openai",
      "mode": "completion"
    },
    {
      "model_name": "davinci-002",
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000002,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "text-completion-openai",
      "mode": "completion"
    },
    {
      "model_name": "gpt-3.5-turbo-instruct",
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "text-completion-openai",
      "mode": "completion"
    },
    {
      "model_name": "gpt-3.5-turbo-instruct-0914",
      "max_tokens": 4097,
      "max_input_tokens": 8192,
      "max_output_tokens": 4097,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "text-completion-openai",
      "mode": "completion"
    },
    {
      "model_name": "claude-instant-1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000163,
      "output_cost_per_token": 0.00000551,
      "litellm_provider": "anthropic",
      "mode": "chat"
    },
    {
      "model_name": "mistral/mistral-tiny",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 2.5e-7,
      "litellm_provider": "mistral",
      "mode": "chat",
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/mistral-small",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "mistral",
      "supports_function_calling": true,
      "mode": "chat",
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/mistral-small-latest",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "mistral",
      "supports_function_calling": true,
      "mode": "chat",
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/mistral-medium",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.0000027,
      "output_cost_per_token": 0.0000081,
      "litellm_provider": "mistral",
      "mode": "chat",
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/mistral-medium-latest",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.0000027,
      "output_cost_per_token": 0.0000081,
      "litellm_provider": "mistral",
      "mode": "chat",
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/mistral-medium-2312",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.0000027,
      "output_cost_per_token": 0.0000081,
      "litellm_provider": "mistral",
      "mode": "chat",
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/mistral-large-latest",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000009,
      "litellm_provider": "mistral",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/mistral-large-2402",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000004,
      "output_cost_per_token": 0.000012,
      "litellm_provider": "mistral",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/mistral-large-2407",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000009,
      "litellm_provider": "mistral",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/open-mistral-7b",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 2.5e-7,
      "litellm_provider": "mistral",
      "mode": "chat",
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/open-mixtral-8x7b",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 7e-7,
      "output_cost_per_token": 7e-7,
      "litellm_provider": "mistral",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/open-mixtral-8x22b",
      "max_tokens": 8191,
      "max_input_tokens": 64000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000002,
      "output_cost_per_token": 0.000006,
      "litellm_provider": "mistral",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/codestral-latest",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "mistral",
      "mode": "chat",
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/codestral-2405",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "mistral",
      "mode": "chat",
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/open-mistral-nemo",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 3e-7,
      "litellm_provider": "mistral",
      "mode": "chat",
      "source": "https://mistral.ai/technology/",
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/open-mistral-nemo-2407",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 3e-7,
      "litellm_provider": "mistral",
      "mode": "chat",
      "source": "https://mistral.ai/technology/",
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/open-codestral-mamba",
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 2.5e-7,
      "litellm_provider": "mistral",
      "mode": "chat",
      "source": "https://mistral.ai/technology/",
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/codestral-mamba-latest",
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 2.5e-7,
      "litellm_provider": "mistral",
      "mode": "chat",
      "source": "https://mistral.ai/technology/",
      "supports_assistant_prefill": true
    },
    {
      "model_name": "mistral/mistral-embed",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "input_cost_per_token": 1e-7,
      "litellm_provider": "mistral",
      "mode": "embedding"
    },
    {
      "model_name": "deepseek-chat",
      "max_tokens": 4096,
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.4e-7,
      "input_cost_per_token_cache_hit": 1.4e-8,
      "output_cost_per_token": 2.8e-7,
      "litellm_provider": "deepseek",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_assistant_prefill": true,
      "supports_tool_choice": true
    },
    {
      "model_name": "codestral/codestral-latest",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "codestral",
      "mode": "chat",
      "source": "https://docs.mistral.ai/capabilities/code_generation/",
      "supports_assistant_prefill": true
    },
    {
      "model_name": "codestral/codestral-2405",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "codestral",
      "mode": "chat",
      "source": "https://docs.mistral.ai/capabilities/code_generation/",
      "supports_assistant_prefill": true
    },
    {
      "model_name": "text-completion-codestral/codestral-latest",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "text-completion-codestral",
      "mode": "completion",
      "source": "https://docs.mistral.ai/capabilities/code_generation/"
    },
    {
      "model_name": "text-completion-codestral/codestral-2405",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "text-completion-codestral",
      "mode": "completion",
      "source": "https://docs.mistral.ai/capabilities/code_generation/"
    },
    {
      "model_name": "deepseek-coder",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.4e-7,
      "input_cost_per_token_cache_hit": 1.4e-8,
      "output_cost_per_token": 2.8e-7,
      "litellm_provider": "deepseek",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_assistant_prefill": true,
      "supports_tool_choice": true
    },
    {
      "model_name": "groq/llama2-70b-4096",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-7,
      "output_cost_per_token": 8e-7,
      "litellm_provider": "groq",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "groq/llama3-8b-8192",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 8e-8,
      "litellm_provider": "groq",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "groq/llama3-70b-8192",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5.9e-7,
      "output_cost_per_token": 7.9e-7,
      "litellm_provider": "groq",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "groq/llama-3.1-8b-instant",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5.9e-7,
      "output_cost_per_token": 7.9e-7,
      "litellm_provider": "groq",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "groq/llama-3.1-70b-versatile",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5.9e-7,
      "output_cost_per_token": 7.9e-7,
      "litellm_provider": "groq",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "groq/llama-3.1-405b-reasoning",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5.9e-7,
      "output_cost_per_token": 7.9e-7,
      "litellm_provider": "groq",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "groq/mixtral-8x7b-32768",
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2.4e-7,
      "output_cost_per_token": 2.4e-7,
      "litellm_provider": "groq",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "groq/gemma-7b-it",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7e-8,
      "output_cost_per_token": 7e-8,
      "litellm_provider": "groq",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "groq/llama3-groq-70b-8192-tool-use-preview",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 8.9e-7,
      "output_cost_per_token": 8.9e-7,
      "litellm_provider": "groq",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "groq/llama3-groq-8b-8192-tool-use-preview",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.9e-7,
      "output_cost_per_token": 1.9e-7,
      "litellm_provider": "groq",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "friendliai/mixtral-8x7b-instruct-v0-1",
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 4e-7,
      "output_cost_per_token": 4e-7,
      "litellm_provider": "friendliai",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "friendliai/meta-llama-3-8b-instruct",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "litellm_provider": "friendliai",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "friendliai/meta-llama-3-70b-instruct",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 8e-7,
      "output_cost_per_token": 8e-7,
      "litellm_provider": "friendliai",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "claude-instant-1.2",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 1.63e-7,
      "output_cost_per_token": 5.51e-7,
      "litellm_provider": "anthropic",
      "mode": "chat"
    },
    {
      "model_name": "claude-2",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "anthropic",
      "mode": "chat"
    },
    {
      "model_name": "claude-2.1",
      "max_tokens": 8191,
      "max_input_tokens": 200000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "anthropic",
      "mode": "chat"
    },
    {
      "model_name": "claude-3-haiku-20240307",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 0.00000125,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 264,
      "supports_assistant_prefill": true
    },
    {
      "model_name": "claude-3-opus-20240229",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000075,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 395,
      "supports_assistant_prefill": true
    },
    {
      "model_name": "claude-3-sonnet-20240229",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_assistant_prefill": true
    },
    {
      "model_name": "claude-3-5-sonnet-20240620",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "anthropic",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_assistant_prefill": true
    },
    {
      "model_name": "text-bison",
      "max_tokens": 2048,
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-text-models",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "text-bison@001",
      "max_tokens": 1024,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-text-models",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "text-bison@002",
      "max_tokens": 1024,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-text-models",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "text-bison32k",
      "max_tokens": 1024,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-text-models",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "text-bison32k@002",
      "max_tokens": 1024,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-text-models",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "text-unicorn",
      "max_tokens": 1024,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.000028,
      "litellm_provider": "vertex_ai-text-models",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "text-unicorn@001",
      "max_tokens": 1024,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.000028,
      "litellm_provider": "vertex_ai-text-models",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "chat-bison",
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-chat-models",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "chat-bison@001",
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-chat-models",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "chat-bison@002",
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-chat-models",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "chat-bison-32k",
      "max_tokens": 8192,
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-chat-models",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "chat-bison-32k@002",
      "max_tokens": 8192,
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-chat-models",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "code-bison",
      "max_tokens": 1024,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-code-text-models",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "code-bison@001",
      "max_tokens": 1024,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "code-bison@002",
      "max_tokens": 1024,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "code-bison32k",
      "max_tokens": 1024,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "code-bison-32k@002",
      "max_tokens": 1024,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "code-gecko@001",
      "max_tokens": 64,
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "litellm_provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "code-gecko@002",
      "max_tokens": 64,
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "litellm_provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "code-gecko",
      "max_tokens": 64,
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "litellm_provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "code-gecko-latest",
      "max_tokens": 64,
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "litellm_provider": "vertex_ai-code-text-models",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "codechat-bison@latest",
      "max_tokens": 1024,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-code-chat-models",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "codechat-bison",
      "max_tokens": 1024,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-code-chat-models",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "codechat-bison@001",
      "max_tokens": 1024,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-code-chat-models",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "codechat-bison@002",
      "max_tokens": 1024,
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-code-chat-models",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "codechat-bison-32k",
      "max_tokens": 8192,
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-code-chat-models",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "codechat-bison-32k@002",
      "max_tokens": 8192,
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "input_cost_per_character": 2.5e-7,
      "output_cost_per_character": 5e-7,
      "litellm_provider": "vertex_ai-code-chat-models",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini-pro",
      "max_tokens": 8192,
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.0025,
      "input_cost_per_video_per_second": 0.002,
      "input_cost_per_token": 5e-7,
      "input_cost_per_character": 1.25e-7,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_character": 3.75e-7,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    {
      "model_name": "gemini-1.0-pro",
      "max_tokens": 8192,
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.0025,
      "input_cost_per_video_per_second": 0.002,
      "input_cost_per_token": 5e-7,
      "input_cost_per_character": 1.25e-7,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_character": 3.75e-7,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models"
    },
    {
      "model_name": "gemini-1.0-pro-001",
      "max_tokens": 8192,
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.0025,
      "input_cost_per_video_per_second": 0.002,
      "input_cost_per_token": 5e-7,
      "input_cost_per_character": 1.25e-7,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_character": 3.75e-7,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini-1.0-ultra",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_image": 0.0025,
      "input_cost_per_video_per_second": 0.002,
      "input_cost_per_token": 5e-7,
      "input_cost_per_character": 1.25e-7,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_character": 3.75e-7,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini-1.0-ultra-001",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_image": 0.0025,
      "input_cost_per_video_per_second": 0.002,
      "input_cost_per_token": 5e-7,
      "input_cost_per_character": 1.25e-7,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_character": 3.75e-7,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini-1.0-pro-002",
      "max_tokens": 8192,
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.0025,
      "input_cost_per_video_per_second": 0.002,
      "input_cost_per_token": 5e-7,
      "input_cost_per_character": 1.25e-7,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_character": 3.75e-7,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini-1.5-pro",
      "max_tokens": 8192,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.001315,
      "input_cost_per_audio_per_second": 0.000125,
      "input_cost_per_video_per_second": 0.001315,
      "input_cost_per_token": 0.000005,
      "input_cost_per_character": 0.00000125,
      "input_cost_per_token_above_128k_tokens": 0.00001,
      "input_cost_per_character_above_128k_tokens": 0.0000025,
      "output_cost_per_token": 0.000015,
      "output_cost_per_character": 0.00000375,
      "output_cost_per_token_above_128k_tokens": 0.00003,
      "output_cost_per_character_above_128k_tokens": 0.0000075,
      "output_cost_per_image": 0.00263,
      "output_cost_per_video_per_second": 0.00263,
      "output_cost_per_audio_per_second": 0.00025,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini-1.5-pro-001",
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.001315,
      "input_cost_per_audio_per_second": 0.000125,
      "input_cost_per_video_per_second": 0.001315,
      "input_cost_per_token": 0.000005,
      "input_cost_per_character": 0.00000125,
      "input_cost_per_token_above_128k_tokens": 0.00001,
      "input_cost_per_character_above_128k_tokens": 0.0000025,
      "output_cost_per_token": 0.000015,
      "output_cost_per_character": 0.00000375,
      "output_cost_per_token_above_128k_tokens": 0.00003,
      "output_cost_per_character_above_128k_tokens": 0.0000075,
      "output_cost_per_image": 0.00263,
      "output_cost_per_video_per_second": 0.00263,
      "output_cost_per_audio_per_second": 0.00025,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini-1.5-pro-preview-0514",
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.001315,
      "input_cost_per_audio_per_second": 0.000125,
      "input_cost_per_video_per_second": 0.001315,
      "input_cost_per_token": 0.000005,
      "input_cost_per_character": 0.00000125,
      "input_cost_per_token_above_128k_tokens": 0.00001,
      "input_cost_per_character_above_128k_tokens": 0.0000025,
      "output_cost_per_token": 0.000015,
      "output_cost_per_character": 0.00000375,
      "output_cost_per_token_above_128k_tokens": 0.00003,
      "output_cost_per_character_above_128k_tokens": 0.0000075,
      "output_cost_per_image": 0.00263,
      "output_cost_per_video_per_second": 0.00263,
      "output_cost_per_audio_per_second": 0.00025,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini-1.5-pro-preview-0215",
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.001315,
      "input_cost_per_audio_per_second": 0.000125,
      "input_cost_per_video_per_second": 0.001315,
      "input_cost_per_token": 0.000005,
      "input_cost_per_character": 0.00000125,
      "input_cost_per_token_above_128k_tokens": 0.00001,
      "input_cost_per_character_above_128k_tokens": 0.0000025,
      "output_cost_per_token": 0.000015,
      "output_cost_per_character": 0.00000375,
      "output_cost_per_token_above_128k_tokens": 0.00003,
      "output_cost_per_character_above_128k_tokens": 0.0000075,
      "output_cost_per_image": 0.00263,
      "output_cost_per_video_per_second": 0.00263,
      "output_cost_per_audio_per_second": 0.00025,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini-1.5-pro-preview-0409",
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_image": 0.001315,
      "input_cost_per_audio_per_second": 0.000125,
      "input_cost_per_video_per_second": 0.001315,
      "input_cost_per_token": 0.000005,
      "input_cost_per_character": 0.00000125,
      "input_cost_per_token_above_128k_tokens": 0.00001,
      "input_cost_per_character_above_128k_tokens": 0.0000025,
      "output_cost_per_token": 0.000015,
      "output_cost_per_character": 0.00000375,
      "output_cost_per_token_above_128k_tokens": 0.00003,
      "output_cost_per_character_above_128k_tokens": 0.0000075,
      "output_cost_per_image": 0.00263,
      "output_cost_per_video_per_second": 0.00263,
      "output_cost_per_audio_per_second": 0.00025,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini-1.5-flash",
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_image": 0.0001315,
      "input_cost_per_video_per_second": 0.0001315,
      "input_cost_per_audio_per_second": 0.000125,
      "input_cost_per_token": 5e-7,
      "input_cost_per_character": 1.25e-7,
      "input_cost_per_token_above_128k_tokens": 0.000001,
      "input_cost_per_character_above_128k_tokens": 2.5e-7,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_character": 3.75e-7,
      "output_cost_per_token_above_128k_tokens": 0.000003,
      "output_cost_per_character_above_128k_tokens": 7.5e-7,
      "output_cost_per_image": 0.000263,
      "output_cost_per_video_per_second": 0.000263,
      "output_cost_per_audio_per_second": 0.00025,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini-1.5-flash-001",
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_image": 0.0001315,
      "input_cost_per_video_per_second": 0.0001315,
      "input_cost_per_audio_per_second": 0.000125,
      "input_cost_per_token": 5e-7,
      "input_cost_per_character": 1.25e-7,
      "input_cost_per_token_above_128k_tokens": 0.000001,
      "input_cost_per_character_above_128k_tokens": 2.5e-7,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_character": 3.75e-7,
      "output_cost_per_token_above_128k_tokens": 0.000003,
      "output_cost_per_character_above_128k_tokens": 7.5e-7,
      "output_cost_per_image": 0.000263,
      "output_cost_per_video_per_second": 0.000263,
      "output_cost_per_audio_per_second": 0.00025,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini-1.5-flash-preview-0514",
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_image": 0.0001315,
      "input_cost_per_video_per_second": 0.0001315,
      "input_cost_per_audio_per_second": 0.000125,
      "input_cost_per_token": 5e-7,
      "input_cost_per_character": 1.25e-7,
      "input_cost_per_token_above_128k_tokens": 0.000001,
      "input_cost_per_character_above_128k_tokens": 2.5e-7,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_character": 3.75e-7,
      "output_cost_per_token_above_128k_tokens": 0.000003,
      "output_cost_per_character_above_128k_tokens": 7.5e-7,
      "output_cost_per_image": 0.000263,
      "output_cost_per_video_per_second": 0.000263,
      "output_cost_per_audio_per_second": 0.00025,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini-pro-experimental",
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "input_cost_per_character": 0,
      "output_cost_per_character": 0,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": false,
      "supports_tool_choice": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental"
    },
    {
      "model_name": "gemini-pro-flash",
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "input_cost_per_character": 0,
      "output_cost_per_character": 0,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "supports_function_calling": false,
      "supports_tool_choice": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental"
    },
    {
      "model_name": "gemini-pro-vision",
      "max_tokens": 2048,
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "max_images_per_prompt": 16,
      "max_videos_per_prompt": 1,
      "max_video_length": 2,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 5e-7,
      "litellm_provider": "vertex_ai-vision-models",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini-1.0-pro-vision",
      "max_tokens": 2048,
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "max_images_per_prompt": 16,
      "max_videos_per_prompt": 1,
      "max_video_length": 2,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 5e-7,
      "litellm_provider": "vertex_ai-vision-models",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini-1.0-pro-vision-001",
      "max_tokens": 2048,
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "max_images_per_prompt": 16,
      "max_videos_per_prompt": 1,
      "max_video_length": 2,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 5e-7,
      "litellm_provider": "vertex_ai-vision-models",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "medlm-medium",
      "max_tokens": 8192,
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_character": 5e-7,
      "output_cost_per_character": 0.000001,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "medlm-large",
      "max_tokens": 1024,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_character": 0.000005,
      "output_cost_per_character": 0.000015,
      "litellm_provider": "vertex_ai-language-models",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "vertex_ai/claude-3-sonnet@20240229",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_assistant_prefill": true
    },
    {
      "model_name": "vertex_ai/claude-3-5-sonnet@20240620",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_assistant_prefill": true
    },
    {
      "model_name": "vertex_ai/claude-3-haiku@20240307",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 0.00000125,
      "litellm_provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_assistant_prefill": true
    },
    {
      "model_name": "vertex_ai/claude-3-opus@20240229",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000075,
      "litellm_provider": "vertex_ai-anthropic_models",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_assistant_prefill": true
    },
    {
      "model_name": "vertex_ai/meta/llama3-405b-instruct-maas",
      "max_tokens": 32000,
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "vertex_ai-llama_models",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models"
    },
    {
      "model_name": "vertex_ai/mistral-large@latest",
      "max_tokens": 8191,
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000009,
      "litellm_provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "vertex_ai/mistral-large@2407",
      "max_tokens": 8191,
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000009,
      "litellm_provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "vertex_ai/mistral-nemo@latest",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "vertex_ai/jamba-1.5-mini@001",
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 4e-7,
      "litellm_provider": "vertex_ai-ai21_models",
      "mode": "chat"
    },
    {
      "model_name": "vertex_ai/jamba-1.5-large@001",
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 0.000002,
      "output_cost_per_token": 0.000008,
      "litellm_provider": "vertex_ai-ai21_models",
      "mode": "chat"
    },
    {
      "model_name": "vertex_ai/jamba-1.5",
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 4e-7,
      "litellm_provider": "vertex_ai-ai21_models",
      "mode": "chat"
    },
    {
      "model_name": "vertex_ai/jamba-1.5-mini",
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 4e-7,
      "litellm_provider": "vertex_ai-ai21_models",
      "mode": "chat"
    },
    {
      "model_name": "vertex_ai/jamba-1.5-large",
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 0.000002,
      "output_cost_per_token": 0.000008,
      "litellm_provider": "vertex_ai-ai21_models",
      "mode": "chat"
    },
    {
      "model_name": "vertex_ai/mistral-nemo@2407",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "vertex_ai/codestral@latest",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "vertex_ai/codestral@2405",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "vertex_ai-mistral_models",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "vertex_ai/imagegeneration@006",
      "cost_per_image": 0.02,
      "litellm_provider": "vertex_ai-image-models",
      "mode": "image_generation",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    {
      "model_name": "vertex_ai/imagen-3.0-generate-001",
      "cost_per_image": 0.04,
      "litellm_provider": "vertex_ai-image-models",
      "mode": "image_generation",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    {
      "model_name": "vertex_ai/imagen-3.0-fast-generate-001",
      "cost_per_image": 0.02,
      "litellm_provider": "vertex_ai-image-models",
      "mode": "image_generation",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    {
      "model_name": "text-embedding-004",
      "max_tokens": 3072,
      "max_input_tokens": 3072,
      "output_vector_size": 768,
      "input_cost_per_token": 6.25e-9,
      "output_cost_per_token": 0,
      "litellm_provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models"
    },
    {
      "model_name": "text-multilingual-embedding-002",
      "max_tokens": 2048,
      "max_input_tokens": 2048,
      "output_vector_size": 768,
      "input_cost_per_token": 6.25e-9,
      "output_cost_per_token": 0,
      "litellm_provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models"
    },
    {
      "model_name": "textembedding-gecko",
      "max_tokens": 3072,
      "max_input_tokens": 3072,
      "output_vector_size": 768,
      "input_cost_per_token": 6.25e-9,
      "output_cost_per_token": 0,
      "litellm_provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "textembedding-gecko-multilingual",
      "max_tokens": 3072,
      "max_input_tokens": 3072,
      "output_vector_size": 768,
      "input_cost_per_token": 6.25e-9,
      "output_cost_per_token": 0,
      "litellm_provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "textembedding-gecko-multilingual@001",
      "max_tokens": 3072,
      "max_input_tokens": 3072,
      "output_vector_size": 768,
      "input_cost_per_token": 6.25e-9,
      "output_cost_per_token": 0,
      "litellm_provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "textembedding-gecko@001",
      "max_tokens": 3072,
      "max_input_tokens": 3072,
      "output_vector_size": 768,
      "input_cost_per_token": 6.25e-9,
      "output_cost_per_token": 0,
      "litellm_provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "textembedding-gecko@003",
      "max_tokens": 3072,
      "max_input_tokens": 3072,
      "output_vector_size": 768,
      "input_cost_per_token": 6.25e-9,
      "output_cost_per_token": 0,
      "litellm_provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "text-embedding-preview-0409",
      "max_tokens": 3072,
      "max_input_tokens": 3072,
      "output_vector_size": 768,
      "input_cost_per_token": 6.25e-9,
      "input_cost_per_token_batch_requests": 5e-9,
      "output_cost_per_token": 0,
      "litellm_provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    {
      "model_name": "text-multilingual-embedding-preview-0409",
      "max_tokens": 3072,
      "max_input_tokens": 3072,
      "output_vector_size": 768,
      "input_cost_per_token": 6.25e-9,
      "output_cost_per_token": 0,
      "litellm_provider": "vertex_ai-embedding-models",
      "mode": "embedding",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "palm/chat-bison",
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "litellm_provider": "palm",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "palm/chat-bison-001",
      "max_tokens": 4096,
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "litellm_provider": "palm",
      "mode": "chat",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "palm/text-bison",
      "max_tokens": 1024,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "litellm_provider": "palm",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "palm/text-bison-001",
      "max_tokens": 1024,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "litellm_provider": "palm",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "palm/text-bison-safety-off",
      "max_tokens": 1024,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "litellm_provider": "palm",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "palm/text-bison-safety-recitation-off",
      "max_tokens": 1024,
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 1.25e-7,
      "litellm_provider": "palm",
      "mode": "completion",
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini/gemini-1.5-flash",
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_token_above_128k_tokens": 7e-7,
      "output_cost_per_token": 0.00000105,
      "output_cost_per_token_above_128k_tokens": 0.0000021,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini/gemini-1.5-flash-latest",
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "max_images_per_prompt": 3000,
      "max_videos_per_prompt": 10,
      "max_video_length": 1,
      "max_audio_length_hours": 8.4,
      "max_audio_per_prompt": 1,
      "max_pdf_size_mb": 30,
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_token_above_128k_tokens": 7e-7,
      "output_cost_per_token": 0.00000105,
      "output_cost_per_token_above_128k_tokens": 0.0000021,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini/gemini-pro",
      "max_tokens": 8192,
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_token_above_128k_tokens": 7e-7,
      "output_cost_per_token": 0.00000105,
      "output_cost_per_token_above_128k_tokens": 0.0000021,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini/gemini-1.5-pro",
      "max_tokens": 8192,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0000035,
      "input_cost_per_token_above_128k_tokens": 0.000007,
      "output_cost_per_token": 0.0000105,
      "output_cost_per_token_above_128k_tokens": 0.000021,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "source": "https://ai.google.dev/pricing"
    },
    {
      "model_name": "gemini/gemini-1.5-pro-exp-0801",
      "max_tokens": 8192,
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0000035,
      "input_cost_per_token_above_128k_tokens": 0.000007,
      "output_cost_per_token": 0.0000105,
      "output_cost_per_token_above_128k_tokens": 0.000021,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "source": "https://ai.google.dev/pricing"
    },
    {
      "model_name": "gemini/gemini-1.5-pro-latest",
      "max_tokens": 8192,
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0000035,
      "input_cost_per_token_above_128k_tokens": 0.000007,
      "output_cost_per_token": 0.00000105,
      "output_cost_per_token_above_128k_tokens": 0.000021,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_system_messages": true,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_tool_choice": true,
      "supports_response_schema": true,
      "source": "https://ai.google.dev/pricing"
    },
    {
      "model_name": "gemini/gemini-pro-vision",
      "max_tokens": 2048,
      "max_input_tokens": 30720,
      "max_output_tokens": 2048,
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_token_above_128k_tokens": 7e-7,
      "output_cost_per_token": 0.00000105,
      "output_cost_per_token_above_128k_tokens": 0.0000021,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini/gemini-gemma-2-27b-it",
      "max_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3.5e-7,
      "output_cost_per_token": 0.00000105,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "gemini/gemini-gemma-2-9b-it",
      "max_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3.5e-7,
      "output_cost_per_token": 0.00000105,
      "litellm_provider": "gemini",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    {
      "model_name": "command-r",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "cohere_chat",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "command-light",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "cohere_chat",
      "mode": "chat"
    },
    {
      "model_name": "command-r-plus",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "cohere_chat",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "command-nightly",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "cohere",
      "mode": "completion"
    },
    {
      "model_name": "command",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "cohere",
      "mode": "completion"
    },
    {
      "model_name": "command-medium-beta",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "cohere",
      "mode": "completion"
    },
    {
      "model_name": "command-xlarge-beta",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "cohere",
      "mode": "completion"
    },
    {
      "model_name": "embed-english-v3.0",
      "max_tokens": 512,
      "max_input_tokens": 512,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "cohere",
      "mode": "embedding"
    },
    {
      "model_name": "embed-english-light-v3.0",
      "max_tokens": 512,
      "max_input_tokens": 512,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "cohere",
      "mode": "embedding"
    },
    {
      "model_name": "embed-multilingual-v3.0",
      "max_tokens": 512,
      "max_input_tokens": 512,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "cohere",
      "mode": "embedding"
    },
    {
      "model_name": "embed-english-v2.0",
      "max_tokens": 512,
      "max_input_tokens": 512,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "cohere",
      "mode": "embedding"
    },
    {
      "model_name": "embed-english-light-v2.0",
      "max_tokens": 512,
      "max_input_tokens": 512,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "cohere",
      "mode": "embedding"
    },
    {
      "model_name": "embed-multilingual-v2.0",
      "max_tokens": 256,
      "max_input_tokens": 256,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "cohere",
      "mode": "embedding"
    },
    {
      "model_name": "replicate/meta/llama-2-13b",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 5e-7,
      "litellm_provider": "replicate",
      "mode": "chat"
    },
    {
      "model_name": "replicate/meta/llama-2-13b-chat",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 5e-7,
      "litellm_provider": "replicate",
      "mode": "chat"
    },
    {
      "model_name": "replicate/meta/llama-2-70b",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6.5e-7,
      "output_cost_per_token": 0.00000275,
      "litellm_provider": "replicate",
      "mode": "chat"
    },
    {
      "model_name": "replicate/meta/llama-2-70b-chat",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6.5e-7,
      "output_cost_per_token": 0.00000275,
      "litellm_provider": "replicate",
      "mode": "chat"
    },
    {
      "model_name": "replicate/meta/llama-2-7b",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 2.5e-7,
      "litellm_provider": "replicate",
      "mode": "chat"
    },
    {
      "model_name": "replicate/meta/llama-2-7b-chat",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 2.5e-7,
      "litellm_provider": "replicate",
      "mode": "chat"
    },
    {
      "model_name": "replicate/meta/llama-3-70b",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 6.5e-7,
      "output_cost_per_token": 0.00000275,
      "litellm_provider": "replicate",
      "mode": "chat"
    },
    {
      "model_name": "replicate/meta/llama-3-70b-instruct",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 6.5e-7,
      "output_cost_per_token": 0.00000275,
      "litellm_provider": "replicate",
      "mode": "chat"
    },
    {
      "model_name": "replicate/meta/llama-3-8b",
      "max_tokens": 8086,
      "max_input_tokens": 8086,
      "max_output_tokens": 8086,
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 2.5e-7,
      "litellm_provider": "replicate",
      "mode": "chat"
    },
    {
      "model_name": "replicate/meta/llama-3-8b-instruct",
      "max_tokens": 8086,
      "max_input_tokens": 8086,
      "max_output_tokens": 8086,
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 2.5e-7,
      "litellm_provider": "replicate",
      "mode": "chat"
    },
    {
      "model_name": "replicate/mistralai/mistral-7b-v0.1",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 2.5e-7,
      "litellm_provider": "replicate",
      "mode": "chat"
    },
    {
      "model_name": "replicate/mistralai/mistral-7b-instruct-v0.2",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-8,
      "output_cost_per_token": 2.5e-7,
      "litellm_provider": "replicate",
      "mode": "chat"
    },
    {
      "model_name": "replicate/mistralai/mixtral-8x7b-instruct-v0.1",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 0.000001,
      "litellm_provider": "replicate",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/deepseek/deepseek-coder",
      "max_tokens": 4096,
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.4e-7,
      "output_cost_per_token": 2.8e-7,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/microsoft/wizardlm-2-8x22b:nitro",
      "max_tokens": 65536,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000001,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/google/gemini-pro-1.5",
      "max_tokens": 8192,
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0000025,
      "output_cost_per_token": 0.0000075,
      "input_cost_per_image": 0.00265,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "openrouter/mistralai/mixtral-8x22b-instruct",
      "max_tokens": 65536,
      "input_cost_per_token": 6.5e-7,
      "output_cost_per_token": 6.5e-7,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/cohere/command-r-plus",
      "max_tokens": 128000,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/databricks/dbrx-instruct",
      "max_tokens": 32768,
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 6e-7,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/anthropic/claude-3-haiku",
      "max_tokens": 200000,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 0.00000125,
      "input_cost_per_image": 0.0004,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "openrouter/anthropic/claude-3-haiku-20240307",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 0.00000125,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 264
    },
    {
      "model_name": "openrouter/anthropic/claude-3.5-sonnet",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159,
      "supports_assistant_prefill": true
    },
    {
      "model_name": "openrouter/anthropic/claude-3.5-sonnet:beta",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 159
    },
    {
      "model_name": "openrouter/anthropic/claude-3-sonnet",
      "max_tokens": 200000,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "input_cost_per_image": 0.0048,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "openrouter/mistralai/mistral-large",
      "max_tokens": 32000,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/cognitivecomputations/dolphin-mixtral-8x7b",
      "max_tokens": 32769,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/google/gemini-pro-vision",
      "max_tokens": 45875,
      "input_cost_per_token": 1.25e-7,
      "output_cost_per_token": 3.75e-7,
      "input_cost_per_image": 0.0025,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "openrouter/fireworks/firellava-13b",
      "max_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/meta-llama/llama-3-8b-instruct:free",
      "max_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/meta-llama/llama-3-8b-instruct:extended",
      "max_tokens": 16384,
      "input_cost_per_token": 2.25e-7,
      "output_cost_per_token": 0.00000225,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/meta-llama/llama-3-70b-instruct:nitro",
      "max_tokens": 8192,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/meta-llama/llama-3-70b-instruct",
      "max_tokens": 8192,
      "input_cost_per_token": 5.9e-7,
      "output_cost_per_token": 7.9e-7,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/openai/gpt-4o",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "openrouter/openai/gpt-4o-2024-05-13",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "openrouter/openai/gpt-4-vision-preview",
      "max_tokens": 130000,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00003,
      "input_cost_per_image": 0.01445,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "openrouter/openai/gpt-3.5-turbo",
      "max_tokens": 4095,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/openai/gpt-3.5-turbo-16k",
      "max_tokens": 16383,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000004,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/openai/gpt-4",
      "max_tokens": 8192,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.00006,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/anthropic/claude-instant-v1",
      "max_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000163,
      "output_cost_per_token": 0.00000551,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/anthropic/claude-2",
      "max_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00001102,
      "output_cost_per_token": 0.00003268,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/anthropic/claude-3-opus",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000075,
      "litellm_provider": "openrouter",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true,
      "tool_use_system_prompt_tokens": 395
    },
    {
      "model_name": "openrouter/google/palm-2-chat-bison",
      "max_tokens": 25804,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/google/palm-2-codechat-bison",
      "max_tokens": 20070,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/meta-llama/llama-2-13b-chat",
      "max_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/meta-llama/llama-2-70b-chat",
      "max_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/meta-llama/codellama-34b-instruct",
      "max_tokens": 8192,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/nousresearch/nous-hermes-llama2-13b",
      "max_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/mancer/weaver",
      "max_tokens": 8000,
      "input_cost_per_token": 0.000005625,
      "output_cost_per_token": 0.000005625,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/gryphe/mythomax-l2-13b",
      "max_tokens": 8192,
      "input_cost_per_token": 0.000001875,
      "output_cost_per_token": 0.000001875,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/jondurbin/airoboros-l2-70b-2.1",
      "max_tokens": 4096,
      "input_cost_per_token": 0.000013875,
      "output_cost_per_token": 0.000013875,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/undi95/remm-slerp-l2-13b",
      "max_tokens": 6144,
      "input_cost_per_token": 0.000001875,
      "output_cost_per_token": 0.000001875,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/pygmalionai/mythalion-13b",
      "max_tokens": 4096,
      "input_cost_per_token": 0.000001875,
      "output_cost_per_token": 0.000001875,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/mistralai/mistral-7b-instruct",
      "max_tokens": 8192,
      "input_cost_per_token": 1.3e-7,
      "output_cost_per_token": 1.3e-7,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "openrouter/mistralai/mistral-7b-instruct:free",
      "max_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "openrouter",
      "mode": "chat"
    },
    {
      "model_name": "j2-ultra",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "ai21",
      "mode": "completion"
    },
    {
      "model_name": "jamba-1.5-mini@001",
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 4e-7,
      "litellm_provider": "ai21",
      "mode": "chat"
    },
    {
      "model_name": "jamba-1.5-large@001",
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 0.000002,
      "output_cost_per_token": 0.000008,
      "litellm_provider": "ai21",
      "mode": "chat"
    },
    {
      "model_name": "jamba-1.5",
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 4e-7,
      "litellm_provider": "ai21",
      "mode": "chat"
    },
    {
      "model_name": "jamba-1.5-mini",
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 4e-7,
      "litellm_provider": "ai21",
      "mode": "chat"
    },
    {
      "model_name": "jamba-1.5-large",
      "max_tokens": 256000,
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 0.000002,
      "output_cost_per_token": 0.000008,
      "litellm_provider": "ai21",
      "mode": "chat"
    },
    {
      "model_name": "j2-mid",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00001,
      "output_cost_per_token": 0.00001,
      "litellm_provider": "ai21",
      "mode": "completion"
    },
    {
      "model_name": "j2-light",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "ai21",
      "mode": "completion"
    },
    {
      "model_name": "dolphin",
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "litellm_provider": "nlp_cloud",
      "mode": "completion"
    },
    {
      "model_name": "chatdolphin",
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "litellm_provider": "nlp_cloud",
      "mode": "chat"
    },
    {
      "model_name": "luminous-base",
      "max_tokens": 2048,
      "input_cost_per_token": 0.00003,
      "output_cost_per_token": 0.000033,
      "litellm_provider": "aleph_alpha",
      "mode": "completion"
    },
    {
      "model_name": "luminous-base-control",
      "max_tokens": 2048,
      "input_cost_per_token": 0.0000375,
      "output_cost_per_token": 0.00004125,
      "litellm_provider": "aleph_alpha",
      "mode": "chat"
    },
    {
      "model_name": "luminous-extended",
      "max_tokens": 2048,
      "input_cost_per_token": 0.000045,
      "output_cost_per_token": 0.0000495,
      "litellm_provider": "aleph_alpha",
      "mode": "completion"
    },
    {
      "model_name": "luminous-extended-control",
      "max_tokens": 2048,
      "input_cost_per_token": 0.00005625,
      "output_cost_per_token": 0.000061875,
      "litellm_provider": "aleph_alpha",
      "mode": "chat"
    },
    {
      "model_name": "luminous-supreme",
      "max_tokens": 2048,
      "input_cost_per_token": 0.000175,
      "output_cost_per_token": 0.0001925,
      "litellm_provider": "aleph_alpha",
      "mode": "completion"
    },
    {
      "model_name": "luminous-supreme-control",
      "max_tokens": 2048,
      "input_cost_per_token": 0.00021875,
      "output_cost_per_token": 0.000240625,
      "litellm_provider": "aleph_alpha",
      "mode": "chat"
    },
    {
      "model_name": "ai21.j2-mid-v1",
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.0000125,
      "output_cost_per_token": 0.0000125,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "ai21.j2-ultra-v1",
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.0000188,
      "output_cost_per_token": 0.0000188,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "ai21.jamba-instruct-v1:0",
      "max_tokens": 4096,
      "max_input_tokens": 70000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 7e-7,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_system_messages": true
    },
    {
      "model_name": "amazon.titan-text-lite-v1",
      "max_tokens": 4000,
      "max_input_tokens": 42000,
      "max_output_tokens": 4000,
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 4e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "amazon.titan-text-express-v1",
      "max_tokens": 8000,
      "max_input_tokens": 42000,
      "max_output_tokens": 8000,
      "input_cost_per_token": 0.0000013,
      "output_cost_per_token": 0.0000017,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "amazon.titan-embed-text-v1",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "output_vector_size": 1536,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "bedrock",
      "mode": "embedding"
    },
    {
      "model_name": "amazon.titan-embed-text-v2:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "output_vector_size": 1024,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "bedrock",
      "mode": "embedding"
    },
    {
      "model_name": "mistral.mistral-7b-instruct-v0:2",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 2e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "mistral.mixtral-8x7b-instruct-v0:1",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 4.5e-7,
      "output_cost_per_token": 7e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "mistral.mistral-large-2402-v1:0",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "mistral.mistral-large-2407-v1:0",
      "max_tokens": 8191,
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000009,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "mistral.mistral-small-2402-v1:0",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 4.5e-7,
      "output_cost_per_token": 7e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 4.5e-7,
      "output_cost_per_token": 7e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 5.9e-7,
      "output_cost_per_token": 9.1e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 2e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 2e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2.6e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/mistral.mistral-large-2402-v1:0",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-2/mistral.mistral-large-2402-v1:0",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "bedrock/eu-west-3/mistral.mistral-large-2402-v1:0",
      "max_tokens": 8191,
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.0000104,
      "output_cost_per_token": 0.0000312,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "anthropic.claude-3-sonnet-20240229-v1:0",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "anthropic.claude-3-5-sonnet-20240620-v1:0",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "anthropic.claude-3-haiku-20240307-v1:0",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 0.00000125,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "anthropic.claude-3-opus-20240229-v1:0",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000075,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "us.anthropic.claude-3-sonnet-20240229-v1:0",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "us.anthropic.claude-3-haiku-20240307-v1:0",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 0.00000125,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "us.anthropic.claude-3-opus-20240229-v1:0",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000075,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "eu.anthropic.claude-3-sonnet-20240229-v1:0",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "eu.anthropic.claude-3-5-sonnet-20240620-v1:0",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "eu.anthropic.claude-3-haiku-20240307-v1:0",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 0.00000125,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "eu.anthropic.claude-3-opus-20240229-v1:0",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "output_cost_per_token": 0.000075,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_vision": true
    },
    {
      "model_name": "anthropic.claude-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/anthropic.claude-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-2/anthropic.claude-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ap-northeast-1/anthropic.claude-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.0455,
      "output_cost_per_second": 0.0455,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.02527,
      "output_cost_per_second": 0.02527,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-central-1/anthropic.claude-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.0415,
      "output_cost_per_second": 0.0415,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.02305,
      "output_cost_per_second": 0.02305,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/1-month-commitment/anthropic.claude-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.0175,
      "output_cost_per_second": 0.0175,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/6-month-commitment/anthropic.claude-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.00972,
      "output_cost_per_second": 0.00972,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-2/1-month-commitment/anthropic.claude-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.0175,
      "output_cost_per_second": 0.0175,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-2/6-month-commitment/anthropic.claude-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.00972,
      "output_cost_per_second": 0.00972,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "anthropic.claude-v2",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/anthropic.claude-v2",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-2/anthropic.claude-v2",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ap-northeast-1/anthropic.claude-v2",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.0455,
      "output_cost_per_second": 0.0455,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.02527,
      "output_cost_per_second": 0.02527,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-central-1/anthropic.claude-v2",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.0415,
      "output_cost_per_second": 0.0415,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.02305,
      "output_cost_per_second": 0.02305,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.0175,
      "output_cost_per_second": 0.0175,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.00972,
      "output_cost_per_second": 0.00972,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.0175,
      "output_cost_per_second": 0.0175,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.00972,
      "output_cost_per_second": 0.00972,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "anthropic.claude-v2:1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/anthropic.claude-v2:1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-2/anthropic.claude-v2:1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ap-northeast-1/anthropic.claude-v2:1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.0455,
      "output_cost_per_second": 0.0455,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.02527,
      "output_cost_per_second": 0.02527,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-central-1/anthropic.claude-v2:1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "output_cost_per_token": 0.000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.0415,
      "output_cost_per_second": 0.0415,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.02305,
      "output_cost_per_second": 0.02305,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.0175,
      "output_cost_per_second": 0.0175,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.00972,
      "output_cost_per_second": 0.00972,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.0175,
      "output_cost_per_second": 0.0175,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.00972,
      "output_cost_per_second": 0.00972,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "anthropic.claude-instant-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000163,
      "output_cost_per_token": 0.00000551,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/anthropic.claude-instant-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 8e-7,
      "output_cost_per_token": 0.0000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.011,
      "output_cost_per_second": 0.011,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.00611,
      "output_cost_per_second": 0.00611,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.011,
      "output_cost_per_second": 0.011,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.00611,
      "output_cost_per_second": 0.00611,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-2/anthropic.claude-instant-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 8e-7,
      "output_cost_per_token": 0.0000024,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ap-northeast-1/anthropic.claude-instant-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000223,
      "output_cost_per_token": 0.00000755,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.01475,
      "output_cost_per_second": 0.01475,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.008194,
      "output_cost_per_second": 0.008194,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-central-1/anthropic.claude-instant-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000248,
      "output_cost_per_token": 0.00000838,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.01635,
      "output_cost_per_second": 0.01635,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1",
      "max_tokens": 8191,
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_second": 0.009083,
      "output_cost_per_second": 0.009083,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "cohere.command-text-v14",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "output_cost_per_token": 0.000002,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/*/1-month-commitment/cohere.command-text-v14",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_second": 0.011,
      "output_cost_per_second": 0.011,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/*/6-month-commitment/cohere.command-text-v14",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_second": 0.0066027,
      "output_cost_per_second": 0.0066027,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "cohere.command-light-text-v14",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 6e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/*/1-month-commitment/cohere.command-light-text-v14",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_second": 0.001902,
      "output_cost_per_second": 0.001902,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/*/6-month-commitment/cohere.command-light-text-v14",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_second": 0.0011416,
      "output_cost_per_second": 0.0011416,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "cohere.command-r-plus-v1:0",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "cohere.command-r-v1:0",
      "max_tokens": 4096,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "cohere.embed-english-v3",
      "max_tokens": 512,
      "max_input_tokens": 512,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "bedrock",
      "mode": "embedding"
    },
    {
      "model_name": "cohere.embed-multilingual-v3",
      "max_tokens": 512,
      "max_input_tokens": 512,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "bedrock",
      "mode": "embedding"
    },
    {
      "model_name": "meta.llama2-13b-chat-v1",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7.5e-7,
      "output_cost_per_token": 0.000001,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "meta.llama2-70b-chat-v1",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000195,
      "output_cost_per_token": 0.00000256,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "meta.llama3-8b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 6e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/meta.llama3-8b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 6e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-1/meta.llama3-8b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 6e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3.6e-7,
      "output_cost_per_token": 7.2e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3.5e-7,
      "output_cost_per_token": 6.9e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3.2e-7,
      "output_cost_per_token": 6.5e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3.9e-7,
      "output_cost_per_token": 7.8e-7,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 0.00000101,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "meta.llama3-70b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000265,
      "output_cost_per_token": 0.0000035,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-east-1/meta.llama3-70b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000265,
      "output_cost_per_token": 0.0000035,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/us-west-1/meta.llama3-70b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000265,
      "output_cost_per_token": 0.0000035,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000318,
      "output_cost_per_token": 0.0000042,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000305,
      "output_cost_per_token": 0.00000403,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000286,
      "output_cost_per_token": 0.00000378,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000345,
      "output_cost_per_token": 0.00000455,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000445,
      "output_cost_per_token": 0.00000588,
      "litellm_provider": "bedrock",
      "mode": "chat"
    },
    {
      "model_name": "meta.llama3-1-8b-instruct-v1:0",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 2.2e-7,
      "output_cost_per_token": 2.2e-7,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": false
    },
    {
      "model_name": "meta.llama3-1-70b-instruct-v1:0",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 9.9e-7,
      "output_cost_per_token": 9.9e-7,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": false
    },
    {
      "model_name": "meta.llama3-1-405b-instruct-v1:0",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000532,
      "output_cost_per_token": 0.000016,
      "litellm_provider": "bedrock",
      "mode": "chat",
      "supports_function_calling": true,
      "supports_tool_choice": false
    },
    {
      "model_name": "512-x-512/50-steps/stability.stable-diffusion-xl-v0",
      "max_tokens": 77,
      "max_input_tokens": 77,
      "output_cost_per_image": 0.018,
      "litellm_provider": "bedrock",
      "mode": "image_generation"
    },
    {
      "model_name": "512-x-512/max-steps/stability.stable-diffusion-xl-v0",
      "max_tokens": 77,
      "max_input_tokens": 77,
      "output_cost_per_image": 0.036,
      "litellm_provider": "bedrock",
      "mode": "image_generation"
    },
    {
      "model_name": "max-x-max/50-steps/stability.stable-diffusion-xl-v0",
      "max_tokens": 77,
      "max_input_tokens": 77,
      "output_cost_per_image": 0.036,
      "litellm_provider": "bedrock",
      "mode": "image_generation"
    },
    {
      "model_name": "max-x-max/max-steps/stability.stable-diffusion-xl-v0",
      "max_tokens": 77,
      "max_input_tokens": 77,
      "output_cost_per_image": 0.072,
      "litellm_provider": "bedrock",
      "mode": "image_generation"
    },
    {
      "model_name": "1024-x-1024/50-steps/stability.stable-diffusion-xl-v1",
      "max_tokens": 77,
      "max_input_tokens": 77,
      "output_cost_per_image": 0.04,
      "litellm_provider": "bedrock",
      "mode": "image_generation"
    },
    {
      "model_name": "1024-x-1024/max-steps/stability.stable-diffusion-xl-v1",
      "max_tokens": 77,
      "max_input_tokens": 77,
      "output_cost_per_image": 0.08,
      "litellm_provider": "bedrock",
      "mode": "image_generation"
    },
    {
      "model_name": "sagemaker/meta-textgeneration-llama-2-7b",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "sagemaker",
      "mode": "completion"
    },
    {
      "model_name": "sagemaker/meta-textgeneration-llama-2-7b-f",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "sagemaker",
      "mode": "chat"
    },
    {
      "model_name": "sagemaker/meta-textgeneration-llama-2-13b",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "sagemaker",
      "mode": "completion"
    },
    {
      "model_name": "sagemaker/meta-textgeneration-llama-2-13b-f",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "sagemaker",
      "mode": "chat"
    },
    {
      "model_name": "sagemaker/meta-textgeneration-llama-2-70b",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "sagemaker",
      "mode": "completion"
    },
    {
      "model_name": "sagemaker/meta-textgeneration-llama-2-70b-b-f",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "sagemaker",
      "mode": "chat"
    },
    {
      "model_name": "together-ai-up-to-4b",
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 1e-7,
      "litellm_provider": "together_ai"
    },
    {
      "model_name": "together-ai-4.1b-8b",
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "litellm_provider": "together_ai"
    },
    {
      "model_name": "together-ai-8.1b-21b",
      "max_tokens": 1000,
      "input_cost_per_token": 3e-7,
      "output_cost_per_token": 3e-7,
      "litellm_provider": "together_ai"
    },
    {
      "model_name": "together-ai-21.1b-41b",
      "input_cost_per_token": 8e-7,
      "output_cost_per_token": 8e-7,
      "litellm_provider": "together_ai"
    },
    {
      "model_name": "together-ai-41.1b-80b",
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "litellm_provider": "together_ai"
    },
    {
      "model_name": "together-ai-81.1b-110b",
      "input_cost_per_token": 0.0000018,
      "output_cost_per_token": 0.0000018,
      "litellm_provider": "together_ai"
    },
    {
      "model_name": "together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1",
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 6e-7,
      "litellm_provider": "together_ai",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    {
      "model_name": "together_ai/mistralai/Mistral-7B-Instruct-v0.1",
      "litellm_provider": "together_ai",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    {
      "model_name": "together_ai/togethercomputer/CodeLlama-34b-Instruct",
      "litellm_provider": "together_ai",
      "supports_function_calling": true,
      "supports_parallel_function_calling": true
    },
    {
      "model_name": "ollama/codegemma",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "completion"
    },
    {
      "model_name": "ollama/codegeex4",
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "chat",
      "supports_function_calling": false
    },
    {
      "model_name": "ollama/deepseek-coder-v2-instruct",
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "ollama/deepseek-coder-v2-base",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "completion",
      "supports_function_calling": true
    },
    {
      "model_name": "ollama/deepseek-coder-v2-lite-instruct",
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "ollama/deepseek-coder-v2-lite-base",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "completion",
      "supports_function_calling": true
    },
    {
      "model_name": "ollama/internlm2_5-20b-chat",
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "ollama/llama2",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "completion"
    },
    {
      "model_name": "ollama/llama2:7b",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "completion"
    },
    {
      "model_name": "ollama/llama2:13b",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "completion"
    },
    {
      "model_name": "ollama/llama2:70b",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "completion"
    },
    {
      "model_name": "ollama/llama2-uncensored",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "completion"
    },
    {
      "model_name": "ollama/llama3",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "chat"
    },
    {
      "model_name": "ollama/llama3:8b",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "chat"
    },
    {
      "model_name": "ollama/llama3:70b",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "chat"
    },
    {
      "model_name": "ollama/llama3.1",
      "max_tokens": 32768,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "chat",
      "supports_function_calling": true
    },
    {
      "model_name": "ollama/mistral-large-instruct-2407",
      "max_tokens": 65536,
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "chat"
    },
    {
      "model_name": "ollama/mistral",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "completion"
    },
    {
      "model_name": "ollama/mistral-7B-Instruct-v0.1",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "chat"
    },
    {
      "model_name": "ollama/mistral-7B-Instruct-v0.2",
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "chat"
    },
    {
      "model_name": "ollama/mixtral-8x7B-Instruct-v0.1",
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "chat"
    },
    {
      "model_name": "ollama/mixtral-8x22B-Instruct-v0.1",
      "max_tokens": 65536,
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "chat"
    },
    {
      "model_name": "ollama/codellama",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "completion"
    },
    {
      "model_name": "ollama/orca-mini",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "completion"
    },
    {
      "model_name": "ollama/vicuna",
      "max_tokens": 2048,
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0,
      "litellm_provider": "ollama",
      "mode": "completion"
    },
    {
      "model_name": "deepinfra/lizpreciatior/lzlv_70b_fp16_hf",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-7,
      "output_cost_per_token": 9e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/Gryphe/MythoMax-L2-13b",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.2e-7,
      "output_cost_per_token": 2.2e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/mistralai/Mistral-7B-Instruct-v0.1",
      "max_tokens": 8191,
      "max_input_tokens": 32768,
      "max_output_tokens": 8191,
      "input_cost_per_token": 1.3e-7,
      "output_cost_per_token": 1.3e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/meta-llama/Llama-2-70b-chat-hf",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-7,
      "output_cost_per_token": 9e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/cognitivecomputations/dolphin-2.6-mixtral-8x7b",
      "max_tokens": 8191,
      "max_input_tokens": 32768,
      "max_output_tokens": 8191,
      "input_cost_per_token": 2.7e-7,
      "output_cost_per_token": 2.7e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/codellama/CodeLlama-34b-Instruct-hf",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 6e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/deepinfra/mixtral",
      "max_tokens": 4096,
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.7e-7,
      "output_cost_per_token": 2.7e-7,
      "litellm_provider": "deepinfra",
      "mode": "completion"
    },
    {
      "model_name": "deepinfra/Phind/Phind-CodeLlama-34B-v2",
      "max_tokens": 4096,
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 6e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1",
      "max_tokens": 8191,
      "max_input_tokens": 32768,
      "max_output_tokens": 8191,
      "input_cost_per_token": 2.7e-7,
      "output_cost_per_token": 2.7e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/deepinfra/airoboros-70b",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-7,
      "output_cost_per_token": 9e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/01-ai/Yi-34B-Chat",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 6e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/01-ai/Yi-6B-200K",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.3e-7,
      "output_cost_per_token": 1.3e-7,
      "litellm_provider": "deepinfra",
      "mode": "completion"
    },
    {
      "model_name": "deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-7,
      "output_cost_per_token": 9e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/meta-llama/Llama-2-13b-chat-hf",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.2e-7,
      "output_cost_per_token": 2.2e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/amazon/MistralLite",
      "max_tokens": 8191,
      "max_input_tokens": 32768,
      "max_output_tokens": 8191,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/meta-llama/Llama-2-7b-chat-hf",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.3e-7,
      "output_cost_per_token": 1.3e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/meta-llama/Meta-Llama-3-8B-Instruct",
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "max_output_tokens": 4096,
      "input_cost_per_token": 8e-8,
      "output_cost_per_token": 8e-8,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/meta-llama/Meta-Llama-3-70B-Instruct",
      "max_tokens": 8191,
      "max_input_tokens": 8191,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5.9e-7,
      "output_cost_per_token": 7.9e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "deepinfra/01-ai/Yi-34B-200K",
      "max_tokens": 4096,
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 6e-7,
      "litellm_provider": "deepinfra",
      "mode": "completion"
    },
    {
      "model_name": "deepinfra/openchat/openchat_3.5",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.3e-7,
      "output_cost_per_token": 1.3e-7,
      "litellm_provider": "deepinfra",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/codellama-34b-instruct",
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 3.5e-7,
      "output_cost_per_token": 0.0000014,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/codellama-70b-instruct",
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 7e-7,
      "output_cost_per_token": 0.0000028,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/llama-3.1-70b-instruct",
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000001,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/llama-3.1-8b-instruct",
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/llama-3.1-sonar-huge-128k-online",
      "max_tokens": 127072,
      "max_input_tokens": 127072,
      "max_output_tokens": 127072,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000005,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/llama-3.1-sonar-large-128k-online",
      "max_tokens": 127072,
      "max_input_tokens": 127072,
      "max_output_tokens": 127072,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000001,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/llama-3.1-sonar-large-128k-chat",
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000001,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/llama-3.1-sonar-small-128k-chat",
      "max_tokens": 131072,
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/llama-3.1-sonar-small-128k-online",
      "max_tokens": 127072,
      "max_input_tokens": 127072,
      "max_output_tokens": 127072,
      "input_cost_per_token": 2e-7,
      "output_cost_per_token": 2e-7,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/pplx-7b-chat",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7e-8,
      "output_cost_per_token": 2.8e-7,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/pplx-70b-chat",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-7,
      "output_cost_per_token": 0.0000028,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/pplx-7b-online",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "output_cost_per_token": 2.8e-7,
      "input_cost_per_request": 0.005,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/pplx-70b-online",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0.0000028,
      "input_cost_per_request": 0.005,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/llama-2-70b-chat",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-7,
      "output_cost_per_token": 0.0000028,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/mistral-7b-instruct",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-8,
      "output_cost_per_token": 2.8e-7,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/mixtral-8x7b-instruct",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-8,
      "output_cost_per_token": 2.8e-7,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/sonar-small-chat",
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 7e-8,
      "output_cost_per_token": 2.8e-7,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/sonar-small-online",
      "max_tokens": 12000,
      "max_input_tokens": 12000,
      "max_output_tokens": 12000,
      "input_cost_per_token": 0,
      "output_cost_per_token": 2.8e-7,
      "input_cost_per_request": 0.005,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/sonar-medium-chat",
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 6e-7,
      "output_cost_per_token": 0.0000018,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "perplexity/sonar-medium-online",
      "max_tokens": 12000,
      "max_input_tokens": 12000,
      "max_output_tokens": 12000,
      "input_cost_per_token": 0,
      "output_cost_per_token": 0.0000018,
      "input_cost_per_request": 0.005,
      "litellm_provider": "perplexity",
      "mode": "chat"
    },
    {
      "model_name": "fireworks_ai/accounts/fireworks/models/firefunction-v2",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "litellm_provider": "fireworks_ai",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://fireworks.ai/pricing"
    },
    {
      "model_name": "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf",
      "max_tokens": 65536,
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.0000012,
      "output_cost_per_token": 0.0000012,
      "litellm_provider": "fireworks_ai",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://fireworks.ai/pricing"
    },
    {
      "model_name": "fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct",
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "litellm_provider": "fireworks_ai",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://fireworks.ai/pricing"
    },
    {
      "model_name": "fireworks_ai/accounts/fireworks/models/yi-large",
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000003,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "fireworks_ai",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://fireworks.ai/pricing"
    },
    {
      "model_name": "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct",
      "max_tokens": 65536,
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0000012,
      "output_cost_per_token": 0.0000012,
      "litellm_provider": "fireworks_ai",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://fireworks.ai/pricing"
    },
    {
      "model_name": "anyscale/mistralai/Mistral-7B-Instruct-v0.1",
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 1.5e-7,
      "litellm_provider": "anyscale",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mistral-7B-Instruct-v0.1"
    },
    {
      "model_name": "anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1",
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 1.5e-7,
      "litellm_provider": "anyscale",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x7B-Instruct-v0.1"
    },
    {
      "model_name": "anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1",
      "max_tokens": 65536,
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_token": 9e-7,
      "output_cost_per_token": 9e-7,
      "litellm_provider": "anyscale",
      "mode": "chat",
      "supports_function_calling": true,
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x22B-Instruct-v0.1"
    },
    {
      "model_name": "anyscale/HuggingFaceH4/zephyr-7b-beta",
      "max_tokens": 16384,
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 1.5e-7,
      "litellm_provider": "anyscale",
      "mode": "chat"
    },
    {
      "model_name": "anyscale/google/gemma-7b-it",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 1.5e-7,
      "litellm_provider": "anyscale",
      "mode": "chat",
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/google-gemma-7b-it"
    },
    {
      "model_name": "anyscale/meta-llama/Llama-2-7b-chat-hf",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 1.5e-7,
      "litellm_provider": "anyscale",
      "mode": "chat"
    },
    {
      "model_name": "anyscale/meta-llama/Llama-2-13b-chat-hf",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "output_cost_per_token": 2.5e-7,
      "litellm_provider": "anyscale",
      "mode": "chat"
    },
    {
      "model_name": "anyscale/meta-llama/Llama-2-70b-chat-hf",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000001,
      "litellm_provider": "anyscale",
      "mode": "chat"
    },
    {
      "model_name": "anyscale/codellama/CodeLlama-34b-Instruct-hf",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000001,
      "litellm_provider": "anyscale",
      "mode": "chat"
    },
    {
      "model_name": "anyscale/codellama/CodeLlama-70b-Instruct-hf",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000001,
      "litellm_provider": "anyscale",
      "mode": "chat",
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/codellama-CodeLlama-70b-Instruct-hf"
    },
    {
      "model_name": "anyscale/meta-llama/Meta-Llama-3-8B-Instruct",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.5e-7,
      "output_cost_per_token": 1.5e-7,
      "litellm_provider": "anyscale",
      "mode": "chat",
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-8B-Instruct"
    },
    {
      "model_name": "anyscale/meta-llama/Meta-Llama-3-70B-Instruct",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000001,
      "litellm_provider": "anyscale",
      "mode": "chat",
      "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-70B-Instruct"
    },
    {
      "model_name": "cloudflare/@cf/meta/llama-2-7b-chat-fp16",
      "max_tokens": 3072,
      "max_input_tokens": 3072,
      "max_output_tokens": 3072,
      "input_cost_per_token": 0.000001923,
      "output_cost_per_token": 0.000001923,
      "litellm_provider": "cloudflare",
      "mode": "chat"
    },
    {
      "model_name": "cloudflare/@cf/meta/llama-2-7b-chat-int8",
      "max_tokens": 2048,
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0.000001923,
      "output_cost_per_token": 0.000001923,
      "litellm_provider": "cloudflare",
      "mode": "chat"
    },
    {
      "model_name": "cloudflare/@cf/mistral/mistral-7b-instruct-v0.1",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000001923,
      "output_cost_per_token": 0.000001923,
      "litellm_provider": "cloudflare",
      "mode": "chat"
    },
    {
      "model_name": "cloudflare/@hf/thebloke/codellama-7b-instruct-awq",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001923,
      "output_cost_per_token": 0.000001923,
      "litellm_provider": "cloudflare",
      "mode": "chat"
    },
    {
      "model_name": "voyage/voyage-01",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "voyage",
      "mode": "embedding"
    },
    {
      "model_name": "voyage/voyage-lite-01",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "voyage",
      "mode": "embedding"
    },
    {
      "model_name": "voyage/voyage-large-2",
      "max_tokens": 16000,
      "max_input_tokens": 16000,
      "input_cost_per_token": 1.2e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "voyage",
      "mode": "embedding"
    },
    {
      "model_name": "voyage/voyage-law-2",
      "max_tokens": 16000,
      "max_input_tokens": 16000,
      "input_cost_per_token": 1.2e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "voyage",
      "mode": "embedding"
    },
    {
      "model_name": "voyage/voyage-code-2",
      "max_tokens": 16000,
      "max_input_tokens": 16000,
      "input_cost_per_token": 1.2e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "voyage",
      "mode": "embedding"
    },
    {
      "model_name": "voyage/voyage-2",
      "max_tokens": 4000,
      "max_input_tokens": 4000,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "voyage",
      "mode": "embedding"
    },
    {
      "model_name": "voyage/voyage-lite-02-instruct",
      "max_tokens": 4000,
      "max_input_tokens": 4000,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "voyage",
      "mode": "embedding"
    },
    {
      "model_name": "databricks/databricks-meta-llama-3-1-405b-instruct",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000005,
      "output_cost_per_token": 0.000015,
      "litellm_provider": "databricks",
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
    },
    {
      "model_name": "databricks/databricks-meta-llama-3-1-70b-instruct",
      "max_tokens": 128000,
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "databricks",
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
    },
    {
      "model_name": "databricks/databricks-dbrx-instruct",
      "max_tokens": 32768,
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 7.5e-7,
      "output_cost_per_token": 0.00000225,
      "litellm_provider": "databricks",
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
    },
    {
      "model_name": "databricks/databricks-meta-llama-3-70b-instruct",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000003,
      "litellm_provider": "databricks",
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
    },
    {
      "model_name": "databricks/databricks-llama-2-70b-chat",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 0.0000015,
      "litellm_provider": "databricks",
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
    },
    {
      "model_name": "databricks/databricks-mixtral-8x7b-instruct",
      "max_tokens": 4096,
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 0.000001,
      "litellm_provider": "databricks",
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
    },
    {
      "model_name": "databricks/databricks-mpt-30b-instruct",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000001,
      "output_cost_per_token": 0.000001,
      "litellm_provider": "databricks",
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
    },
    {
      "model_name": "databricks/databricks-mpt-7b-instruct",
      "max_tokens": 8192,
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5e-7,
      "output_cost_per_token": 5e-7,
      "litellm_provider": "databricks",
      "mode": "chat",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
    },
    {
      "model_name": "databricks/databricks-bge-large-en",
      "max_tokens": 512,
      "max_input_tokens": 512,
      "output_vector_size": 1024,
      "input_cost_per_token": 1e-7,
      "output_cost_per_token": 0,
      "litellm_provider": "databricks",
      "mode": "embedding",
      "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
    }
  ]
  
